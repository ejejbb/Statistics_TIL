# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `3부-13.머신러닝 분석 방법론` 중 p.438(서포트벡터머신)까지를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_6th_TIL

### 3부. 데이터 분석 준비하기
### 13.머신러닝 분석 방법론-1 (13.5.까지)



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|--------------|----------|
|1주차| 1부 ~p.79    | ✅      |
|2주차| 2부 ~p.120   | ✅      | 
|3주차| 2부 ~p.202   | ✅      | 
|4주차| 2부 ~p.299   | ✅      | 
|5주차| 3부 ~p.356   | ✅      | 
|6주차| 3부 ~p.437   | ✅      | 
|7주차| 3부 ~p.542   | 🍽️      | 
|8주차| 3부 ~p.615   | 🍽️      | 
|9주차|데이터 분석 실습| 🍽️      |

<!-- 여기까진 그대로 둬 주세요-->

# 13.머신러닝 분석 방법론-1 (13.5.까지)

```
✅ 학습 목표 :
* 선형 회귀 모델의 기본 개념과 Elastic Net을 활용한 변수 선택 및 모델 정규화 방법을 이해하고 적용할 수 있다.  
* 로지스틱 회귀분석의 개념과 오즈(Odds)의 의미를 이해하고, 이항 분류 문제에 적절히 활용할 수 있다.  
* 의사결정나무와 랜덤 포레스트의 구조, 학습 방식, 과적합 방지 기법을 이해하고 비교할 수 있다.  
* LDA와 QDA의 개념과 차이점을 이해하고, 데이터 특성에 따라 적절한 모델을 선택할 수 있다.
* SVM의 원리와 선형 분리가 어려운 데이터에 대한 커널 트릭 활용 방법을 이해하고, 분류 문제에 적용할 수 있다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

### 13.1. 선형 회귀분석과 Elastic Net(예측모델)

회귀분석은 각 독립변수의 평균을 통해 종속변수를 예측한다. 회귀분석은 종속변수의 값에 영향을 주는 독립변수들의 조건을 고려하여 구한 평균값으로 정의할 수 있다.

$$y=\beta_0+\beta_1X_1+...+\beta_nX_n+\varepsilon$$

```
y: 종속변수, 예측하고자 하는 값
beta: 절편, 각 독립변수가 종속변수에 주는 영향력 값
X: 독ㄼ변수
error: 잔차, 모델에 의해 설명되지 않는 부분
```

최적의 회귀선을 구하는 것을 **모형 적합**이라고 하며 회귀선과 각 관측치를 뜻하는 점 간이 거리를 최소화한다. => 최조제곱추정법(LSE)

```
[회귀분석 시 주의할 점]
- 독립변수 간 상관관계가 없어야 함 -> 다중공선성 검사
- 잔차의 정규성
- 잔차의 등분산성
- 선형성: 독립변수 값의 변화에 따른 종속변 값의 변화는 일정해야 한다. 만일 비선형적인 관계를 갖고 있을 경우 회귀선의 예측력이 떨어짐.
```

```
[다항회귀]
- 독립변수와 종속변수의 관계가 비선형 관계일 때 변수에 각 특성의 제곱을 추가하여 회귀선을 비선형으로 변환
- 차수가 커질수록 편향은 감소하지만 변동성이 증가 -> 과적합 유발
```

다중 회귀분석 변수별 계수 및 유의도 결과를 확인하여 분석가가 변수 조합을 테스트할 수도 있지만 이는 매우 비효율적임 -> 변수 선택 알고리즘

```
[변수 선택 알고리즘]
# 전진 선택법: 유의미한 독립변수 순으로 변수를 차례로 하나씩 추가
# 후진 제거법: 모든 독립변수가 포함된 상태에서 시작하여 유의미하지 않은 설명변수를 하나씩 제거
# 단계적 선택법: 전진선택법 + 후진제거법 : 처음에는 전진선택법처럼 변수를 하나씩 추가하기 시작하면서, 선택된 변수가 3개 이상이 되면 변수 추가와 제거를 번갈아가며 수행
# 그 밖의 변수 선택 알고리즘 : LARS, 유전자 알고리즘, Elastic Net
```

Elastic Net : 릿지, 라쏘 회귀를 조합한 변수 알고리즘
```
# 릿지
 - 전체 변수를 모두 유지하면서 각 변수의 계수 크기를 조정
 - L2-norm
 - 독립변수들의 영향력 조정: 계수 정규화
 - 매개변수 α값을 조정하여 정규화 수준을 조정
 - 제약조건까지 가는 가장 작은 잔차제곱합의 맞닿는 지점의 파라미터 값이 작게라도 존재
 - 변환된 계수가 0이 될 수 없음
# 라쏘
 - 중요한 몇 개의 변수만 선택하고 나머지 변수들은 계수를 0으로 두어 변수의 영향력을 아예 없앰
 - L1-norm
 - 릿지처럼 α값을 조정하여 정규화의 강도를 조정
 - 파라미터 값의 크기에 상관없이 같은 수준으로 정규화를 하기 때문에 영향력이 작ㅇ느 변수를 모델에서 삭제
 - 변환된 계수가 0이 될 수 있음
```
Elastic Net은 혼합비율(r)을 조정하여 모델의 성능을 최적으로 끌어내고자 함. 독립변수를 이미 잘 정제해서 중요할 것으로 판단되는 변수들만 선별해서 모델에 넣은 상태면 릿지의 비율을 높이는 것이 좋고, 변수 선택 없이 주어진 독립변수를 모두 집어넣은 상태라면 라쏘의 비율을 높이는 것이 좋다.

```
[회귀모델 자체에 대한 평가]
- 모델에 대한 유의도
- 모델 설명력: 선택된 독립변수들로 종속변수를 어느 정도 설명할 수 있는지를 판단
- 수정된 모델 설명력: 독립변수의 수가 많아질수록 설명력이 높아지는 경향성을 막기 위한 기준값
```

```
[p-value와 R^2 값에 따른 모델 튜닝 전략]
# 낮은 p-value와 높은 R^2 -> 이상적, 주요 인자 추출
# 낮은 p-value와 낮은 R^2 -> 이상치 제거, 비선형 회귀분석 적용
# 높은 p-value와 높은 R^2 -> 데이터 확보, 이상치 제거
# 높은 p-value와 낮은 R^2 -> 새로운 변수 탐색, 비선형 회귀분석 적용
```

### 13.2. 로지스틱 회귀분석 (분류모델)

```
[로지스틱 회귀분석]
- 종속변수가 질적척도
- 특정 수치를 예측하는 것이 아니라 어떤 카테고리에 들어갈지 분류하는 모델
```
$$Odds = {P(event\ occurring)\over P(event\ not\ occurring)}$$

오즈는 값의 범위가 0부터 무한대까지라는 한계가 있으므로 오즈에 로그를 취하여 양의 무한대에서 음의 무한대를 값으로 가지는 형태로 변환

$$P = {e^{\beta_0+\beta X}\over{1+e^{\beta_0+\beta X}}} = {1\over{1+e^{-(\beta_0+\beta X)}}}$$

다항 로지스틱 회귀분석의 경우, 하나의 범주를 기준으로 잡고 나머지 다른 범주들과 비교해서 식을 만든다. 따라서 다항 로지스틱 회귀분석은 이항 로지스틱 식이 K-1개가 필요하다.



### 13.3. 의사결정나무와 랜덤 포레스트 (예측/분류 모델)

```
[의사결정나무]
- 나뭇가지들이 뻗어 있는 형태로 데이터들이 분리되어 가며 최적의 예측 조건을 만드는 것
- 가지가 나눠지는 부분은 독립변수의 조건이고, 마지막 잎사귀들은 최종의 종속변숫값들을 나타냄
```

```
[의사결정나무의 종류]
# 분류나무: 명목형 종속변수를 분류
 - 불순도를 낮추고 순도를 높이는 방향으로 분류 기준을 찾아냄 -> '지니계수', '엔트로피'를 기준으로 데이터의 불순도를 나타냄 
 - 노드 내에서는 범주의 동직성이 최대한 높고, 노드 간에는 이질성이 최대한 높도록 만들어주는 것
 - 1회 자식노드를 만들기 위해 변수가 k개, 관측치가 n개라면, k(n-1)번의 계산을 하게 됨

# 회귀나무: 연속형의 수를 예측
 - 잔차 제곱합 등의 분류 기준을 사용
 - 구역을 나누어 값을 예측하기 때문에 종속변수의 비선형성에 영향을 받지 않음
 - 끝 노드에 속한 데이터의 값의 평균을 구해 회귀 예측값을 계산
```

```
[의사결정나무의 장단점]
# 장점
 - 해석의 용이성
 - 비선형 모델이므로 데이터의 선형성, 정규성, 등분산성 등이 필요하지 않음
# 단점
 - 명목형 변수는 예측 데이터에 있는 정보가 학습 데이터에 없으면 예측이 불가능하다 -> 예측할 수 있는 종속변수의 최소 최댓값이 학습 데이터의 범위에 한정되므로 학습 데이터와 예측 데이터의 연속형 변숫값 편차가 큰 경우에는 예측력이 떨어질 수 있음
 - 과적합 될 확률이 높음
 - 학습 성능의 변동이 큼
```

```
[의사결정나무의 과적합 방지를 위한 방법]
- 가지치기 : 가지치기 적정 수준 판별은 분기 가지가 많아질수록 학습 데이터의 오분류율은 낮아지게 되고, 특정 수준 이상이 되면 검증 데이터의 오분류율이 높아지는 원리를 이용
- 정보 획득량 임곗값 설정
- 한 노드에 들어가는 최소 데이터 수 제한하기
- 노드의 최대 깊이 제한하기 등
```

```
[랜덤 포레스트]
- 나무를 여러 개 만들어서 학습
- 앙상블 학습

# 부트스트랩: 하나의 데이터셋을 중복을 허용하여 무작위로 여러 번 추출
# 배깅: 여러 개의 의사결정나무를 하나로 합치는 것
```

### 13.4. 선형 판별분석과 이차 판별분석 (분류모델)

```
[판별분석]
- 로지스틱 회귀분석처럼 질적 척도로 이루어진 종속변수를 분류할 때 사용되는 분석 기법
- 성능면에서 로지스틱 회귀분석보다 우수
- 30% 적은 데이터로도 로지스틱 회귀분석과 유사한 성능을 낼 수 있음
- 독립변수들이 정규분포를 따르지 않더라도 활용 가능
```

```
[판별분석 종류]
# 일반 판별분석: 종속변수의 범주가 두 개
# 다중 판별분석: 종속변수의 범주가 3개 이상

[결정경계선 산출 방식]
# 선형판별분석(LDA)
 - PCA와 같은 차원축소에도 사용됨, PCA와 차이점은 종속변수를 사용하는 지도학습으로 차원축소를 한다는 점
 - 조건: 데이터가 정규분포 / 각 범주들은 동일한 공분산 행렬을 가짐 / 독립변수는 통계적으로 상호 독립

# 이차판별분석(QDA)
 - LDA가 공분산 구조가 많이 다른 범주의 데이터를 잘 분류하지 못한다는 단점을 보완한 방법
 - 비선형 분류가 가능하지만 독립변수가 많을 경우 LDA에 비해 연산량이 크다는 단점
```

### 13.5. 서포트벡터머신 (분류모델)

```
[서포트벡터머신(SVM)]
- 범주를 나눠줄 수 있는 최적의 구분선을 찾아내어 관측치의 범주를 예측
- 이진 분류에만 사용 가능
- 마진을 최대화하는 원리로 결정경계선을 설정
```

<br>
<br>

# 확인 문제

## **문제 1. 로지스틱 회귀분석**

> **🧚 용호가 근무하는 한 보험사에서 고객이 보험 상품을 해지할지 여부(0: 유지, 1: 해지)를 예측하기 위해 로지스틱 회귀분석을 수행하려 합니다.**  
> 주요 변수는 `고객 나이`, `계약 기간`, `보험료`, `고객 만족도`입니다.

**🔍 Q1. 용호는 로지스틱 회귀분석을 수행하기 위해 어떤 귀무가설과 대립가설을 세워야 할까요?**  

```
# 귀무가설(H₀): 독립변수(월 사용 요금, 계약 기간, 고객 서비스 이용 여부)는 고객 이탈 여부에 영향을 미치지 않는다. (회귀 계수 β = 0)

# 대립가설(H₁): 최소한 하나의 독립변수는 고객 이탈 여부에 유의미한 영향을 미친다. (회귀 계수 β ≠ 0)
```


**🔍 Q2. (실습문제 추가로 내면 좋을 듯)**

---

## **문제 2. 의사결정나무**

> **🧚 선교가 근무하는 다트비 은행에서 고객의 대출 승인 여부(1: 승인, 0: 거절)를 예측하기 위해 의사결정나무 모델을 구축했습니다. 모델은 다음과 같은 논리 구조를 따릅니다.**  

```yaml
                        [신용 점수 ≥ 700]
                          /        \
                        Yes        No
                       /             \
           [소득 ≥ 4,000만 원]     대출 거절 (0)
              /        \
            Yes        No
           /             \
대출 승인 (1)      대출 거절 (0)
```

**🔍 Q1. 이 의사결정나무가 고객 대출 승인 여부를 예측하는 논리를 설명하세요.**  

```
의사결정나무는 고객의 신용 점수와 소득 수준을 기준으로 대출 승인 여부를 결정한다.

신용 점수 ≥ 700인 경우:
소득 ≥ 4,000만 원이면 대출 승인(1).
소득 < 4,000만 원이면 대출 거절(0).

신용 점수 < 700인 경우:
대출은 무조건 거절(0)

이 구조는 신용 점수를 가장 중요한 변수로 판단하고, 일정 수준 이상일 경우 소득이 추가로 고려되는 방식이다. 즉, 신용 점수가 낮으면 소득 수준과 무관하게 대출이 거절된다.
```

**🔍 Q2. 이 모델이 과적합(overfitting)될 가능성이 있다면, 선교는 이를 방지하기 위해 어떤 방법을 사용할 수 있을까요? 한 가지 이상 제안하세요.**

```
1) 가지치기:
- 불필요한 세부 분기를 제거하여 모델의 복잡도를 줄이는 방법
- 트리의 최대 깊이를 제한하거나, 최소 샘플 분할 수를 설정하여 과도한 학습을 방지할 수 있다.

2) 앙상블 기법 (예: 랜덤 포레스트):
- 단일 트리가 아닌 여러 개의 트리를 생성하고 결과를 종합하여 예측한다.
- 개별 트리의 과적합 위험을 줄이고, 모델의 일반화 성능을 높이는 데 효과적
- 배깅(Bagging) 기법을 통해 데이터 샘플링의 다양성을 확보하여 모델의 안정성을 강화
```

### **🔍 Q3. 로지스틱 회귀분석을 이 문제에 적용할 수 있습니다. 의사결정나무와 로지스틱 회귀분석의 주요 차이점과 이 문제에 대한 적용 시 차이를 간략히 서술하세요.**

```
# 의사결정나무
 - 대출 승인 여부를 명확한 규칙(조건문)으로 분기하여 예측
 => 조건에 따른 승인/거절

# 로지스틱 회귀분석
 - 신용 점수와 소득이 대출 승인 확률에 미치는 영향을 계수(β)로 계산하여 확률 기반으로 예측
 - 변수 간의 선형적인 관계를 가정하며, "신용 점수와 소득이 높을수록 승인 확률이 증가"하는 식으로 해석함
 => 대출 승인 확률 -> 정량적 해석 가능 
```
---
## **문제 3. 로지스틱 회귀 vs SVM**

> **🧚 수연이는 고객의 이탈 여부(0: 유지, 1: 이탈)를 예측하기 위해 로지스틱 회귀분석과 SVM(서포트 벡터 머신) 모델을 적용했습니다. 수연이가 고객 이탈 여부를 예측할 때, 두 모델 중 어떤 상황에서 로지스틱 회귀분석이 더 유리하고, 어떤 상황에서 SVM이 더 유리할지 설명하세요.**

```
# 로지스틱 회귀가 유리한 경우:  
  - 변수의 영향력(계수)을 직관적으로 파악할 수 있기 때문에 변수의 해석이 중요
  - 선형적 관계가 뚜렷한 경우

# SVM이 유리한 경우:  
  - 데이터가 복잡하거나 고차원인 경우  
  - 선형적으로 분리되지 않는 데이터일 때 커널 트릭을 사용해 성능을 개선할 수 있음
```

---

## **문제 4. 회귀 vs. 분류**

> **🧚 경희는 데이터 분석 프로젝트를 진행하면서 아래의 상황에 대해 회귀 분석과 분류 분석 중 어떤 방법이 더 적합할지 고민하고 있습니다. 경희는 각 사례에 대해 어떤 방법을 사용하는 것이 적합할까요? 적합한 분석방법을 선택하고 그 이유를 간단히 설명하세요.**

>**1️⃣ 한 식당의 매출을 예측하기 위해 고객 수, 광고 비용, 날씨 등의 데이터를 활용하는 경우   
2️⃣ 병원에서 환자가 특정 질병에 걸릴 확률을 예측하는 경우   
3️⃣ 한 은행이 대출 신청자의 신용 점수를 기반으로 대출 승인 여부를 결정하는 경우  
4️⃣ 부동산 시장에서 아파트 가격을 예측하는 경우**

```
1️⃣ 회귀: 매출은 연속적인 수치이므로 회귀 모델이 적합
2️⃣ 분류: 질병 유무는 이진 분류 문제로 로지스틱 회귀나 의사결정나무 등이 적합
3️⃣ 분류 분석: 대출 승인 여부는 "승인/거절"의 이진 분류 문제이므로 분류 분석이 적합
4️⃣ 회귀:아파트 가격은 연속형 변수이므로 회귀 모델이 적합
```

### 🎉 수고하셨습니다.